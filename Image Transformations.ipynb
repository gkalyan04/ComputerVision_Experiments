{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translations\n",
    "\n",
    "This is an affine transform that simply shifts the position of an image.\n",
    "\n",
    "We use cv2.warpAffine to implement these transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./input.jpg')\n",
    "\n",
    "# store height and width of the image\n",
    "height, width = image.shape[:2]\n",
    "quarter_height, quarter_width = height/4, width/4\n",
    "\n",
    "#     | 1 0 Tx |\n",
    "# T = | 0 1 Ty |\n",
    "\n",
    "# T is our tanslation matrix\n",
    "T = np.float32([[1,0, quarter_width],[0, 1, quarter_height]])\n",
    "\n",
    "# We us warpAffine to transform the image using the matrix , T\n",
    "img_translation = cv2.warpAffine(image, T, (width,height))\n",
    "cv2.imshow('Translated Image',img_translation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./input1.jpg')\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Divide by two to rotate the image around it's centre\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2,height/2),90,1)\n",
    "\n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (width,height))\n",
    "\n",
    "cv2.imshow('Rotated Image',rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice all the black space surrounding the image\n",
    "we could now crop the image as we calculate it's size\n",
    "\n",
    "But here's another method for simple rotation that uses cv2.transpose function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other option to rotate the image\n",
    "img = cv2.imread('./input.jpg')\n",
    "rotated_img = cv2.transpose(img)\n",
    "\n",
    "cv2.imshow('Rotated Image - Method 2', rotated_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling , Resizing and interpolations\n",
    "Resizing is very easy using cv2.resize function, it's arguments are\n",
    "\n",
    "cv2.resize(image, dsize(output image size), x scale, y scale , interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./input1.jpg')\n",
    "\n",
    "# Let's make our image 3/4 of it's original size\n",
    "image_scaled = cv2.resize(image, None, fx=0.2, fy=0.2)\n",
    "cv2.imshow('Scaling - Linear Interpolation', image_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Let's double the size of our image\n",
    "image_scaled = cv2.resize(image, None, fx=0.2, fy=0.2,interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('Scaling - Cubic Interpolation', image_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Let's skew the re-sizing by setting exact dimensions\n",
    "image_scaled = cv2.resize(image, (900,100),interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('Scaling - Skewed Image', image_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Pyramids\n",
    "Useful when scaling images in object-detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('./input1.jpg')\n",
    "\n",
    "image_scaled = cv2.resize(image, None, fx=0.2, fy=0.2)\n",
    "\n",
    "smaller = cv2.pyrDown(image_scaled)\n",
    "larger = cv2.pyrUp(smaller)\n",
    "\n",
    "cv2.imshow('Original', image_scaled)\n",
    "cv2.imshow('Smaller', smaller)\n",
    "cv2.imshow('Larger', larger)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./input.jpg')\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "start_row, start_col = int(height * .25), int(height * .25)\n",
    "end_row, end_col = int(height * .75),int(width * .75)\n",
    "\n",
    "cropped_image = image[start_row:end_row,start_col:end_col]\n",
    "\n",
    "cv2.imshow('Original Image',image)\n",
    "cv2.imshow('Cropped Image',cropped_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic Operations\n",
    "These are simple operations that allow us to directly add or subtract to the color intensity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./input.jpg')\n",
    "\n",
    "# Create a matrix of ones, then multiply by a scale of 100\n",
    "M = np.ones(image.shape, dtype = 'uint8') * 175\n",
    "\n",
    "# We use this to add this matrix M, to our image\n",
    "\n",
    "# Notice the increase in brightness\n",
    "added = cv2.add(image, M)\n",
    "cv2.imshow('Added', added)\n",
    "\n",
    "# Likewise we can also subtract\n",
    "subtracted = cv2.subtract(image, M)\n",
    "cv2.imshow('Subtracted',subtracted)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitwise Operations and Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Making a square\n",
    "square = np.zeros((300,300), np.uint8)\n",
    "cv2.rectangle(square,(50,50),(250,250),255,-1)\n",
    "cv2.imshow('Square', square)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Making a ellipse\n",
    "ellipse = np.zeros((300,300), np.uint8)\n",
    "cv2.ellipse(ellipse,(150,150),(150,150), 30,0,180,255,-1)\n",
    "cv2.imshow('Ellipse', ellipse)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with some bitwise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows only when they intersect \n",
    "bitwiseAnd = cv2.bitwise_and(square, ellipse)\n",
    "cv2.imshow('AND',bitwiseAnd)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# shows where either sqaure or ellipse is\n",
    "bitwiseOr = cv2.bitwise_or(square, ellipse)\n",
    "cv2.imshow('OR',bitwiseOr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# shows whre either exist by itself\n",
    "bitwiseXor = cv2.bitwise_xor(square, ellipse)\n",
    "cv2.imshow('XOR',bitwiseXor)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Shows everything that isn't part of the square\n",
    "bitwiseNot_sq = cv2.bitwise_not(square)\n",
    "cv2.imshow('NOT - square', bitwiseNot_sq)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions and Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./input.jpg')\n",
    "cv2.imshow('Original Image',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Creating our 3 x 3 kernel\n",
    "kernel_3x3 = np.ones((3,3),np.float32) / 9\n",
    "\n",
    "# We use the cv2.fliter2D to conovlve the kernel with an image\n",
    "blurred = cv2.filter2D(image, -1, kernel_3x3)\n",
    "cv2.imshow('3 X 3 Kernel Blurring', blurred)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Creating our 7 x 7 kernel\n",
    "kernel_7x7 = np.ones((7,7),np.float32) / 49\n",
    "\n",
    "blurred2 = cv2.filter2D(image, -1, kernel_7x7)\n",
    "cv2.imshow('7x7 Kernel Blurring', blurred2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other commonly used blurring methods in openCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./input2.jpg')\n",
    "\n",
    "image_scaled = cv2.resize(image, None, fx=0.15, fy=0.15)\n",
    "\n",
    "blur = cv2.blur(image_scaled,(7,7))\n",
    "cv2.imshow('Averaging', blur)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Instead of box filter, gaussian kernel\n",
    "Gaussian = cv2.GaussianBlur(image_scaled,(7,7), 0)\n",
    "cv2.imshow('Gaussian Blurring',Gaussian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Take median of all the pixels under kernel area and central\n",
    "# element is replaced with this median value\n",
    "median = cv2.medianBlur(image_scaled, 5)\n",
    "cv2.imshow('Median Blurring', median)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Bilateral is very effective in noise removal while keeping edges sharp\n",
    "bilateral = cv2.bilateralFilter(image_scaled, 9, 75, 75)\n",
    "cv2.imshow('Bilateral Blurring', bilateral)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image De-noising - Non-Local Means Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./input3.jpg')\n",
    "\n",
    "image_scaled = cv2.resize(image, None, fx=0.9, fy=0.9)\n",
    "\n",
    "dst = cv2.fastNlMeansDenoisingColored(image_scaled,None,6,6,7,21)\n",
    "\n",
    "cv2.imshow('Fast Means Denoising', dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./input3.jpg')\n",
    "\n",
    "\n",
    "#dst = cv2.fastNlMeansDenoisingColored(image,None,6,6,7,21)\n",
    "\n",
    "kernel_sharpening = np.array([[-1,-0.9,-1],\n",
    "                              [-1.1,9,-1],\n",
    "                              [-1,-0.9,-1]])\n",
    "\n",
    "sharpened = cv2.filter2D(image,-1,kernel_sharpening)\n",
    "\n",
    "cv2.imshow('Image Sharpening',sharpened)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding, Binarization & Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./input3.jpg',0)\n",
    "cv2.imshow('Original', image )\n",
    "\n",
    "ret, thresh1 = cv2.threshold(image, 127,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('1 Threshold binary', thresh1)\n",
    "\n",
    "ret, thresh2 = cv2.threshold(image, 127,255,cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('2 Threshold binary INV', thresh2)\n",
    "\n",
    "ret, thresh3 = cv2.threshold(image, 127,255,cv2.THRESH_TRUNC)\n",
    "cv2.imshow('3 Threshold TRUNC', thresh3)\n",
    "\n",
    "ret, thresh4 = cv2.threshold(image, 127,255,cv2.THRESH_TOZERO)\n",
    "cv2.imshow('4 Threshold TOZERO', thresh4)\n",
    "\n",
    "ret, thresh5 = cv2.threshold(image, 127,255,cv2.THRESH_TOZERO_INV)\n",
    "cv2.imshow('5 Threshold TOZERO INV', thresh5)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Thresholding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./input3.jpg',0)\n",
    "cv2.imshow('Original', image )\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Values below 127 goes to 0 (black, everything above goes to 255(white))\n",
    "ret, thresh1 = cv2.threshold(image,127,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('Threshold binary',thresh1)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# It's good practice to blur i,age as it removes noise\n",
    "image = cv2.GaussianBlur(image,(3,3),0)\n",
    "\n",
    "# Using  adaptiveThreshold\n",
    "thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY, 3, 1)\n",
    "cv2.imshow('Adaptive Mean Thresholding', thresh)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "_, th2 = cv2.threshold(image, 0 ,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Otsu's Thresholding\", th2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv2.GaussianBlur(image,(5,5),0)\n",
    "_, th3 = cv2.threshold(blur,0 , 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "cv2.imshow(\"Gaussian Otsu's Thresholding\",th3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilation, Erosion , Opening and Closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./input.jpg',0)\n",
    "cv2.imshow('Original', image )\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Let's define kernel size \n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "# Now we erode\n",
    "erosion = cv2.erode(image, kernel, iterations=1)\n",
    "cv2.imshow('Erosion',erosion)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "dilation = cv2.dilate(image,kernel, iterations=1)\n",
    "cv2.imshow('Dilation',dilation)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Opening - Good for removing noise\n",
    "opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Opening',opening)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Closing - Good for removing noise\n",
    "closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow('Closing',closing)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection & Image Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./input3.jpg',0)\n",
    "\n",
    "height, width = image.shape\n",
    "\n",
    "# # Exract Sobel Edges\n",
    "# sobel_x = cv2.Sobel(image, cv2.CV_64F, 0 , 1, ksize=5)\n",
    "# sobel_y = cv2.Sobel(image, cv2.CV_64F, 1 , 0, ksize=5)\n",
    "\n",
    "# cv2.imshow('Original',image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.imshow('Sobel X', sobel_x)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.imshow('Sobel Y', sobel_y)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# sobel_OR = cv2.bitwise_or(sobel_x,sobel_y)\n",
    "# cv2.imshow('sobel_OR',sobel_OR)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# laplacian = cv2.Laplacian(image,cv2.CV_64F)\n",
    "# cv2.imshow('Laplacian', laplacian)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# Canny Edge Detection \n",
    "canny = cv2.Canny(image, 30, 110)\n",
    "cv2.imshow('Canny', canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Perpsective Tranform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('./input.jpg')\n",
    "cv2.imshow('Original', image )\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Coordinates of the 4 corners of the original image\n",
    "points_A = np.float32([[320,15],[700,215],[85,610],[530,780]])\n",
    "\n",
    "# we use a ration of an A4 Paper\n",
    "points_B = np.float32([[0,0],[420,0],[0,594],[420,594]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(points_A,points_B)\n",
    "\n",
    "warped = cv2.warpPerspective(image, M,(420,594))\n",
    "\n",
    "cv2.imshow('warpPerspective', warped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
